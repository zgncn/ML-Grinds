{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Karar Ağaçlar:Teori,Matematik ve Uygulama\n",
    "* Karar ağaçları, verileri bölümlere ayırarak sınıflandırma veya regresyon problemlerini çözen bir algotirma türüdür.Ağaç yapısı, iç düğümlerde karar verme koşullarını, dallarda koşulların sonuçlarını ve yapraklarda sınıfları veya değerleri içerir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropi:\n",
    "\n",
    "**  Veri kümesindeki sınıfların ne kadar karışık veya düzensiz olduğunu ölçer.Diyelim ki elimizde elma ve armut içeren bir sepet var\n",
    "\n",
    "** Düşük Entropi(Düşük Belirsizlik):\n",
    "* Sepette 100 elma ve 0 armut var\n",
    "* Rastgele bir meyve seçerseniz , bunun kesinlikle elma olacağını bilirsiniz.Yani belirsizlik yok entropi=0\n",
    "\n",
    "** Orta Entropi(Orta Belirsizlik):\n",
    "* Sepette 80 elma ve 20 armut var\n",
    "* Rasgele bir meyve seçerseniz bunun muhtemelen elma olacağını tahmin edersiniz ama kesin değildir. Yani orta derecede belirsizlik\n",
    "\n",
    "** Yüksek Entropi (Yüksek Belirsizlik)\n",
    "* Sepette 50 elma ve 50 armut var\n",
    "* Rastgele bir meyve seçerseniz, bunun elma veya armut olduğunu tahmin etmeniz zordur. Yani maksimum belirsizlik, entropi maksimum\n",
    "\n",
    "** Matematiksel Formül ve Anlamı\n",
    "\n",
    "$$H(S) = -\\sum_{i=1}^{c} p_i \\log_2(p_i)$$\n",
    "\n",
    "* S=veri kümesi\n",
    "* c=sınıf sayısı\n",
    "* pi=i sınıfındaki örnelerin oranı\n",
    "\n",
    "** Formülün Yorumlanması\n",
    "* Her sınıf için, o sınıfın olasılığının logaritmasını alıp, olasılıkla çarpıyoruz\n",
    "* Bu değerleri tüm sınıflar için toplayıp negatifini alıyoruz\n",
    "* Sonuçta 0 ile log2(c) arasında bir değer elde ederiz\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Karar Ağaçlarında Entropi Kullanımı\n",
    "** Karar ağaçları verileri bölmek için entropi değişimini kullanır\n",
    "* Bir düğümdeki başlangıç entropi değerini hesaplar\n",
    "* Her özellik için, o özelliğe göre bölme sonrası oluşacak entropi değerini hesaplar\n",
    "* Entropi azalmasını(bilgi kazancını) maksimize eden özellik seçilir\n",
    "* Yani düşük entropi= daha homojen alt kümeler= daha iyi bölünme\n",
    "\n",
    "** Örnek Bir Hesaplama.Diyelim ki bir düğümde 6 pozitig, 4 negatif örnek var\n",
    "* p1=6/10=0.6(pozitif örneklerin oranı)\n",
    "* p2=4/10=0.4(negatif örneklerin oranı)\n",
    "* H(S) = entropi, H-->entropi fonksiyonu, S--> veri kümesi\n",
    "* H(S) = -(0.6 x log2(0.6) + 0.4 x log2(0.4))\n",
    "* H(S) = -(0.6 * (-0.737) + 0.4 x (-1.322))\n",
    "* H(S) = - ((-0.442) + (-0.529))\n",
    "* H(S) = 0.971 (bu değer belirsizliği gösterir.1 e yakın bir değer oldukça karmaşık bir veri kümesi anlamına gelir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bilgi Kazancı (Information Gain)\n",
    "\n",
    "** Bilgi kazancı, bir özelliğe göre ve kümesini böldüğümüzde entropideki(belirsizlikteki) azalmayı ölçer.\n",
    "* Basitçe Bilgi Kazancı=Başlangıçtaki Belirsizlik - Bölünme sonrası kalan belirsizlik\n",
    "* Formül olarak\n",
    "\n",
    "$$IG(S,A) = H(S) - \\sum_{v \\in Values(A)} \\frac{|S_v|}{|S|} H(S_v)$$\n",
    "\n",
    "* H(S)= Bölünmeden önceki veri kümesi entropisi\n",
    "* A= Bölünme için kullanılan özellik\n",
    "* Values(A)= A özelliğinin alabileceği değerler\n",
    "* Sv= A özelliğinin v değerini alt küme\n",
    "* |Sv|/|S|= v değerine sahip örneklerin oranı\n",
    "* H(Sv)= v değerine sahip alt kümelerin entropisi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Somut Bir Örnek\n",
    "* Bir karar ağacı oluşturarak elmaları ve armutları sınıflandırmak istediğimizi düşünelim. Elimizde şu veri seti olsun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Meyve</th>\n",
       "      <th>Renk</th>\n",
       "      <th>Ağırlık</th>\n",
       "      <th>Şekil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elma</td>\n",
       "      <td>Kırmızı</td>\n",
       "      <td>Orta</td>\n",
       "      <td>Yuvarlak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elma</td>\n",
       "      <td>Yeşil</td>\n",
       "      <td>Orta</td>\n",
       "      <td>Yuvarlak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elma</td>\n",
       "      <td>Kırmızı</td>\n",
       "      <td>Hafif</td>\n",
       "      <td>Yuvarlak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elma</td>\n",
       "      <td>Sarı</td>\n",
       "      <td>Orta</td>\n",
       "      <td>Yuvarlak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Armut</td>\n",
       "      <td>Yeşil</td>\n",
       "      <td>Ağır</td>\n",
       "      <td>Oval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Armut</td>\n",
       "      <td>Yeşil</td>\n",
       "      <td>Ağır</td>\n",
       "      <td>Oval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Armut</td>\n",
       "      <td>Sarı</td>\n",
       "      <td>Ağır</td>\n",
       "      <td>Oval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Armut</td>\n",
       "      <td>Kırmızı</td>\n",
       "      <td>Orta</td>\n",
       "      <td>Oval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Meyve     Renk Ağırlık     Şekil\n",
       "0   Elma  Kırmızı    Orta  Yuvarlak\n",
       "1   Elma    Yeşil    Orta  Yuvarlak\n",
       "2   Elma  Kırmızı   Hafif  Yuvarlak\n",
       "3   Elma     Sarı    Orta  Yuvarlak\n",
       "4  Armut    Yeşil    Ağır      Oval\n",
       "5  Armut    Yeşil    Ağır      Oval\n",
       "6  Armut     Sarı    Ağır      Oval\n",
       "7  Armut  Kırmızı    Orta      Oval"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame({\"Meyve\":[\"Elma\",\"Elma\",\"Elma\",\"Elma\",\"Armut\",\"Armut\",\"Armut\",\"Armut\"],\n",
    "                 \"Renk\":[\"Kırmızı\",\"Yeşil\",\"Kırmızı\",\"Sarı\",\"Yeşil\",\"Yeşil\",\"Sarı\",\"Kırmızı\"],\n",
    "                 \"Ağırlık\":[\"Orta\",\"Orta\",\"Hafif\",\"Orta\",\"Ağır\",\"Ağır\",\"Ağır\",\"Orta\"],\n",
    "                 \"Şekil\":[\"Yuvarlak\",\"Yuvarlak\",\"Yuvarlak\",\"Yuvarlak\",\"Oval\",\"Oval\",\"Oval\",\"Oval\"]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Elimizde 4 elma ve 4 armut var.Hangi özelliğe göre bölme yapmanın daha iyi olacağını bulmak için bilgi kazancını hesaplarız\n",
    "### Adım 1: Başlangıç Entropisini Hesapla\n",
    "\n",
    "* H(S)=-[0.5 * log2(0.5) + 0.5 * log2(0.5)]\n",
    "* H(S)=-[0.5 * (-1) + 0.5 * (-1)]\n",
    "* H(S)= 1 --> Bu ikisi sınıf için mümkün olan maksimum entropi demektir.Tam dengelenmiş veri kümesi\n",
    "\n",
    "### Adım 2: \"Renk\" Özelliğine Göre Bilgi Kazancını Hesapla -Kırmızı,Yeşil,Sarı-\n",
    "\n",
    "** Kırmızı Alt Kümesi : 2 elma , 1 armut\n",
    "* H(S_kırmızı)= -[2/3 * log2(2/3) + 1/3 * log2(1/3)]=0.918\n",
    "* |S_kırmızı|/|S|=3/8\n",
    "\n",
    "** Yeşil Alt Kümesi : 1 elma, 2 armut\n",
    "* H(S_yeşil)= -[1/3 * log2(1/3) + 2/3 * log2(2/3)]=0.918\n",
    "* |S_yeşil|/|S|=3/8\n",
    "\n",
    "** Sarı Alt Kümesi : 1 armut , 1 elma\n",
    "* H(S_sarı)= -[1/2 * log2(1/2) + 1/2 * log(1/2)]=1\n",
    "* |S_sarı|/|S|=2/8\n",
    "\n",
    "** BİLGİ KAZANCI (RENK):\n",
    "* IG(S,Renk) = H(S) -[(3/8 * 0.918) + (3/8 * 0.918) + (2/8 * 1)]\n",
    "* IG(S,Renk) = 1 - 0.938 = 0.062\n",
    "\n",
    "### Adım 3: \"Şekil\" Özelliğine Göre Bilgi Kazancı -Yuvarlak ve Oval-\n",
    "** Yuvarlak Alt Kümesi : 4 Elma, 0 armut\n",
    "* H(S_yuvarlak) = -[1 * log2(1) + 0 * log2(0)]=0 (tamamen homojen)\n",
    "* |S_yuvarlak|/|S|= 4/8 =0.5\n",
    "** Oval Alt Kümesi : 0 elma, 4 armut\n",
    "* H(S_oval)= - [0 *log2(0) + 1 * log2(1)]=0 (tamamen homojen)\n",
    "* |S_oval|/|S|= 4/8 =0.5\n",
    "\n",
    "** Bilgi Kazancı (Şekil):\n",
    "* IG(S,şekil)=H(S) - [(0.5 * 0) + (0.5 * 0)]\n",
    "* IG(S,şekil)= 1 - 0 = 1  \n",
    "\n",
    "### Adım 4:\"Ağırlık\" Özelliğine Göre Bilgi Kazancı -Orta/hafif ve Ağır-\n",
    "** Orta/Hafif Alt Kümesi : 4 elma 1 armut\n",
    "* H(S_ort_hafif)= -[4/5 * log2(4/5) + 1/5 * log2(1/5)]=0.722\n",
    "* |S_orta_hafif|/|S| = 5/8\n",
    "** Ağır Alt Kümesi : 0 elma 3 armut\n",
    "* H(S_ağır)= -[0 * log2(0) + 1 * log2(1)] = 0\n",
    "* |S_ağır|/|S| = 3/8\n",
    "\n",
    "** Bilgi Kazancı(Ağırlık) :\n",
    "* IG(S,ağırlık) = H(S) -[(5/8 * 0.722) + (3/8 * 0)]\n",
    "* IG(S,ağırlık) = 1- 0.451 = 0.549\n",
    "\n",
    "### Sonuç ve Yorum (Hesapladığımız bilgi kazancı değerleri)\n",
    "* IG(S,renk) = 0.062\n",
    "* IG(S,şekil) = 1\n",
    "* IG(S,Ağırlık) = 0.549\n",
    "\n",
    "** Bu Durumda en yüksek bilgi kazancı \"ŞEKİL\" özelliğine ait(1).Bu şekil özelliğinin veri kümesindeki belirsizliği tamamen ortadan kaldırdığını gösterir.Karar ağaçı algoritması her adımda mevcut veri kümesini en yüksek bilgi kazancını sağlauan özelliğe göre böler.Bu örnekte ilk bölünme şekil özelliğine göre yapılacak ve bölünme sonrasında tam bir sınıflandırma elde edilecektir \n",
    "\n",
    "* Şekil?\n",
    "*    ├── Yuvarlak → Elma\n",
    "*    └── Oval → Armut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GINI INDEKSİ \n",
    "* Gini indeksi (veya gibi safsızlık ölçüsü), karar ağaçları gibi makine öğrnemesi algoritmalarında, özellikle sınıflandırma problemlerinde bir düğümün saflığını ölçmek için kullanılır\n",
    "\n",
    "### Temel Kavram\n",
    "* Gini indeksi bir düğümdeki safsızlığı veya hetorejenliği ölçer. Sıfır değeri mükemmel saflığı(düğümdeki tüm örnekler aynı sınıfa aitse) gösterirken, daha yüksek değerler daha fazla karışıklığı gösterir\n",
    "\n",
    "### Matematiksel Formülasyon\n",
    "\n",
    "$$\\text{Gini} = 1 - \\sum_{i} p_i^2$$\n",
    "\n",
    "* pi, i sınıfının düğümdeki oranıdır\n",
    "\n",
    "### Örnek ile Açıklama --> \n",
    "** Diyelim ki bir düğümde 100 veri noktası var ve bunlar iki sınıfa ayrılıyor\n",
    "* 70 Tanesi sınıf A\n",
    "* 30 Tanesi sınıf B\n",
    "\n",
    "** Gini indeksi hesabı:\n",
    "\n",
    "* Sınıf A oranı: 70/100=0.7\n",
    "* Sınıf B oranı: 30/100=0.3\n",
    "* Gini= 1 - [(0.7)**2 + (0.3)**2] \n",
    "* Gini= 1 - 0.58 = 0.42\n",
    "\n",
    "### Entropi ile Kıyaslarsak\n",
    "* Gini indeksi hesaplaması entropi hesaplamasına göre daha hızlıdır(log hesaplaması yoktur)\n",
    "* İki ölçü de benzer bölünmelere yol açar ama bazı durumlarda farklılıklar olabilir\n",
    "*  Gini , CART algoritmasında kullanılırken, Entropi genellikle ID3 ve C4.5 algoritmalarında kullanılır"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karar Ağaçlarının Çalışma Mantığı\n",
    "\n",
    "** Karar ağaçları temelde veri kümesini özelliklerden biri üzerinde terkarlı olarak bölerek çalışır\n",
    "* Kök düğüm--> Tüm veri burda başlar\n",
    "* Karar düğümleri--> Her düğümde bir özellik ve eşik değeri seçilerek veri iki alt kümeye bölünür\n",
    "* Bölünme kriteri--> Algoritma veirleri en homojenden alt kümelere bölen özelliği ve eşik değerini seçer\n",
    "* Yaprak düğümleri--> Ağacın en alt kısmında yer alan ve tahmin sonuçlarını içeren düğümlerdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sıfırdan Decision Tree İmplementasyonu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Sınıfı\n",
    "* Node sınıfı ağacın her bir düğümünü temsil eder. Bir düğüm ya bi karar düğümüdür(özellik ve eşik değeri vardır) ya da yaprak düğümüdür(sınıf değeri vardır)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    \"\"\"\n",
    "    Karar ağacının her bir düğümünü temsil eden sınıf\n",
    "    \"\"\"\n",
    "    def __init__(self,feature=None,threshold=None,left=None,right=None,value=None):\n",
    "        self.feature=feature #Bölünme yapılacak özellik\n",
    "        self.threshold=threshold\n",
    "        self.left=left\n",
    "        self.right=right\n",
    "        self.value=value\n",
    "    def is_leaf(self):\n",
    "        \"\"\"\n",
    "        Düğümün yaprak olup olmadığını kontrol eder\n",
    "        \"\"\"\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Sınıfı\n",
    "* Bu sınıf karar ağacı algoritmasının ana bileşenidir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk: 0.9667\n",
      "Karmaşıklık Matrisi:\n",
      "[[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n",
      "\n",
      "Karar Ağacı Yapısı:\n",
      "petal length (cm) <= 1.9\n",
      "├── Yes: → setosa\n",
      "└── No:  petal length (cm) <= 4.7\n",
      "    ├── Yes: petal width (cm) <= 1.6\n",
      "        ├── Yes: → versicolor\n",
      "        └── No:  → virginica\n",
      "    └── No:  petal width (cm) <= 1.7\n",
      "        ├── Yes: → virginica\n",
      "        └── No:  → virginica\n",
      "Model doğruluğu: 0.9667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "class Node:\n",
    "    \"\"\"\n",
    "    Karar ağacının her bir düğümünü temsil eden sınıf\n",
    "    \"\"\"\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
    "        self.feature = feature  # Bölünme yapılacak özellik\n",
    "        self.threshold = threshold  # Bölünme eşik değeri\n",
    "        self.left = left  # Sol alt ağaç\n",
    "        self.right = right  # Sağ alt ağaç\n",
    "        self.value = value  # Eğer yaprak düğümse, sınıf etiketi\n",
    "\n",
    "    def is_leaf(self):\n",
    "        \"\"\"\n",
    "        Düğümün yaprak olup olmadığını kontrol eder\n",
    "        \"\"\"\n",
    "        return self.value is not None\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    Karar Ağacı sınıflandırıcısı\n",
    "    \"\"\"\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, criterion=\"gini\"):\n",
    "        \"\"\"\n",
    "        Parametreler:\n",
    "        min_samples_split: Bir düğümün bölünmesi için gereken minimum örnek sayısı\n",
    "        max_depth: Ağacın maksimum derinliği\n",
    "        criterion: Bölünme kriteri ('gini' veya 'entropy')\n",
    "        \"\"\"\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.criterion = criterion\n",
    "        self.root = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Karar ağacını eğitir\n",
    "        X: Özellikler, y: Hedef değişken\n",
    "        \"\"\"\n",
    "        # NumPy dizisine dönüştür\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        \n",
    "        # Özyinelemeli olarak ağacı oluştur\n",
    "        self.root = self._grow_tree(X, y, depth=0)\n",
    "\n",
    "    def _grow_tree(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        Ağacı özyinelemeli olarak büyüten fonksiyon\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        n_classes = len(np.unique(y))\n",
    "        \n",
    "        # Durma kriterleri kontrolü\n",
    "        if (depth >= self.max_depth or n_samples < self.min_samples_split or n_classes == 1):\n",
    "            # Yaprak düğüm oluştur - en sık görülen sınıfı ata\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # En iyi bölünmeyi bul\n",
    "        best_feature, best_threshold = self._best_split(X, y)\n",
    "        \n",
    "        # Eğer iyi bir bölünme bulunamazsa, yaprak döndür\n",
    "        if best_feature is None:\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # Sol ve sağ alt kümeleri oluştur\n",
    "        left_idxs = X[:, best_feature] <= best_threshold\n",
    "        right_idxs = ~left_idxs\n",
    "        \n",
    "        # Sol ve sağ alt ağaçları özyinelemeli olarak büyüt\n",
    "        left_subtree = self._grow_tree(X[left_idxs], y[left_idxs], depth + 1)\n",
    "        right_subtree = self._grow_tree(X[right_idxs], y[right_idxs], depth + 1)\n",
    "        \n",
    "        # Düğümü döndür\n",
    "        return Node(feature=best_feature, threshold=best_threshold, \n",
    "                   left=left_subtree, right=right_subtree)\n",
    "\n",
    "    def _best_split(self, X, y):\n",
    "        \"\"\"\n",
    "        En iyi bölünme noktasını bulan fonksiyon\n",
    "        \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Başlangıçta en iyi değerleri ayarla\n",
    "        best_feature, best_threshold = None, None\n",
    "        best_gain = -np.inf\n",
    "        \n",
    "        # Şu anki saflık ölçüsünü hesapla\n",
    "        current_impurity = self._calculate_impurity(y)\n",
    "        \n",
    "        # Her bir özellik için en iyi bölünmeyi bul\n",
    "        for feature in range(n_features):\n",
    "            # Özellik değerlerini al ve sırala\n",
    "            thresholds = np.unique(X[:, feature])\n",
    "            \n",
    "            # Her bir eşik değeri için bilgi kazancını hesapla\n",
    "            for threshold in thresholds:\n",
    "                # Verileri böl\n",
    "                left_idxs = X[:, feature] <= threshold\n",
    "                right_idxs = ~left_idxs\n",
    "                \n",
    "                # Her iki alt küme de örnekler içermeli\n",
    "                if np.sum(left_idxs) == 0 or np.sum(right_idxs) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Sol ve sağ alt kümeler için saflık hesapla\n",
    "                left_impurity = self._calculate_impurity(y[left_idxs])\n",
    "                right_impurity = self._calculate_impurity(y[right_idxs])\n",
    "                \n",
    "                # Alt kümelerin ağırlıklarını hesapla\n",
    "                n_left, n_right = np.sum(left_idxs), np.sum(right_idxs)\n",
    "                \n",
    "                # Ağırlıklı saflık ölçüsünü hesapla\n",
    "                weighted_impurity = (n_left / n_samples) * left_impurity + \\\n",
    "                                   (n_right / n_samples) * right_impurity\n",
    "                \n",
    "                # Bilgi kazancını hesapla\n",
    "                information_gain = current_impurity - weighted_impurity\n",
    "                \n",
    "                # Daha iyi bir bölünme bulundu mu?\n",
    "                if information_gain > best_gain:\n",
    "                    best_gain = information_gain\n",
    "                    best_feature = feature\n",
    "                    best_threshold = threshold\n",
    "        \n",
    "        return best_feature, best_threshold\n",
    "\n",
    "    def _calculate_impurity(self, y):\n",
    "        \"\"\"\n",
    "        Gini veya Entropy saflık ölçüsünü hesaplar\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        if m == 0:\n",
    "            return 0\n",
    "        \n",
    "        # Sınıf oranlarını hesapla\n",
    "        counts = np.bincount(y)\n",
    "        proportions = counts / m\n",
    "        \n",
    "        if self.criterion == \"gini\":\n",
    "            # Gini safsızlık ölçüsü: 1 - sum(p_i^2)\n",
    "            return 1 - np.sum(proportions ** 2)\n",
    "        else:  # \"entropy\"\n",
    "            # Entropy safsızlık ölçüsü: -sum(p_i * log2(p_i))\n",
    "            # 0 log(0) = 0 olarak kabul ediyoruz\n",
    "            entropy = -np.sum(proportions * np.log2(proportions + 1e-10))\n",
    "            return entropy\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        \"\"\"\n",
    "        En sık görülen sınıf etiketini döndürür\n",
    "        \"\"\"\n",
    "        counter = Counter(y)\n",
    "        return counter.most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X verisi için tahmin yapar\n",
    "        \"\"\"\n",
    "        # NumPy dizisine dönüştür\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # Tek bir örnek için tahmin\n",
    "        if len(X.shape) == 1:\n",
    "            return self._traverse_tree(X, self.root)\n",
    "        \n",
    "        # Birden fazla örnek için tahmin\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
    "\n",
    "    def _traverse_tree(self, x, node):\n",
    "        \"\"\"\n",
    "        Tahmin için ağacı gezer\n",
    "        \"\"\"\n",
    "        # Yaprak düğüme ulaşıldıysa, sınıf etiketini döndür\n",
    "        if node.is_leaf():\n",
    "            return node.value\n",
    "        \n",
    "        # Özellik değerine göre sol veya sağ alt ağaca git\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self._traverse_tree(x, node.left)\n",
    "        return self._traverse_tree(x, node.right)\n",
    "    \n",
    "    def visualize_tree(self, feature_names=None, class_names=None, max_depth=3):\n",
    "        \"\"\"\n",
    "        Karar ağacını görselleştirir (basit text formatında)\n",
    "        \"\"\"\n",
    "        if  feature_names is None:\n",
    "            feature_names = [f\"Feature {i}\" for i in range(100)]  # Varsayılan özellik isimleri\n",
    "        if  class_names is None:\n",
    "            class_names = [str(i) for i in range(100)]  # Varsayılan sınıf isimleri\n",
    "            \n",
    "        def print_tree(node, indent=\"\", depth=0):\n",
    "            if depth > max_depth:\n",
    "                return \"...\"\n",
    "                \n",
    "            if node.is_leaf():\n",
    "                return f\"→ {class_names[node.value]}\"\n",
    "            \n",
    "            feature_name = feature_names[node.feature]\n",
    "            left_text = print_tree(node.left, indent + \"    \", depth + 1)\n",
    "            right_text = print_tree(node.right, indent + \"    \", depth + 1)\n",
    "            \n",
    "            return (f\"{feature_name} <= {node.threshold}\\n\"\n",
    "                   f\"{indent}├── Yes: {left_text}\\n\"\n",
    "                   f\"{indent}└── No:  {right_text}\")\n",
    "        \n",
    "        tree_text = print_tree(self.root)\n",
    "        return tree_text\n",
    "\n",
    "    def plot_decision_boundary(self, X, y, feature_idx=[0, 1], step=0.01):\n",
    "        \"\"\"\n",
    "        2 boyutlu karar sınırlarını çizer\n",
    "        \"\"\"\n",
    "\n",
    "        # X'in orijinal halini sakla \n",
    "        X_orig = X.copy()\n",
    "        # Sadece belirtilen iki özelliği kullan\n",
    "        X = X[:, feature_idx]\n",
    "        \n",
    "        # Karar sınırları için grid oluştur\n",
    "        x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "        y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, step),\n",
    "                             np.arange(y_min, y_max, step))\n",
    "        \n",
    "        # Grid noktalarını tahmin et\n",
    "        Z = np.zeros((xx.shape[0], xx.shape[1]))\n",
    "        for i in range(xx.shape[0]):\n",
    "            for j in range(xx.shape[1]):\n",
    "                # Orijinal X veri setinin tam boyutunu kullan\n",
    "                n_features = X.shape[1] if hasattr(X, 'shape') else 4  # Iris için varsayılan 4\n",
    "                full_features = np.zeros((1, X_orig.shape[1])) #Orijinal X boyutu\n",
    "                full_features[0, feature_idx[0]] = xx[i, j]\n",
    "                full_features[0, feature_idx[1]] = yy[i, j]\n",
    "                Z[i, j] = self.predict(full_features)[0]\n",
    "        \n",
    "        # Karar sınırlarını çiz\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.Paired)\n",
    "        \n",
    "        # Veri noktalarını çiz\n",
    "        scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')\n",
    "        plt.xlabel(f'Feature {feature_idx[0]}')\n",
    "        plt.ylabel(f'Feature {feature_idx[1]}')\n",
    "        plt.title('Decision Boundaries')\n",
    "        \n",
    "        # Legend ekle\n",
    "        legend = plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "        plt.gca().add_artist(legend)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return plt\n",
    "\n",
    "# Test işlevi - karar ağacını Iris veri seti üzerinde değerlendirir\n",
    "def test_decision_tree():\n",
    "    # Iris veri setini yükle\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    feature_names = iris.feature_names\n",
    "    class_names = iris.target_names\n",
    "    \n",
    "    # Eğitim ve test setlerini ayır\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Karar ağacı oluştur ve eğit\n",
    "    dt = DecisionTree(min_samples_split=2, max_depth=3, criterion=\"gini\")\n",
    "    dt.fit(X_train, y_train)\n",
    "    \n",
    "    # Tahminler yap\n",
    "    y_pred = dt.predict(X_test)\n",
    "    \n",
    "    # Performansı değerlendir\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Doğruluk: {accuracy:.4f}\")\n",
    "    print(\"Karmaşıklık Matrisi:\")\n",
    "    print(conf_matrix)\n",
    "    \n",
    "    # Ağacı görselleştir\n",
    "    tree_text = dt.visualize_tree(feature_names, class_names)\n",
    "    print(\"\\nKarar Ağacı Yapısı:\")\n",
    "    print(tree_text)\n",
    "    \n",
    "    # Karar sınırlarını çiz\n",
    "    plt = dt.plot_decision_boundary(X, y, feature_idx=[0, 2], step=0.01)\n",
    "    plt.savefig('decision_boundary.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return dt, accuracy\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dt, accuracy = test_decision_tree()\n",
    "    print(f\"Model doğruluğu: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
