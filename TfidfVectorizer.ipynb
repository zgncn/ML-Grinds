{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer Nedir?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF = Term Frequency * Inverse Document Frequency\n",
    "\n",
    "\n",
    "- TF(Term Frequency): Bir kelimenin dökümanda ne kadar sık geçtiğidir\n",
    "\n",
    "- IDF(Inverse Document Frequency): Bir kelimenin tüm koleksiyonda(tüm dokumanların toplamı,analiz ettiğimiz veri seti) ne kadar nadir olduğudur\n",
    "\n",
    "- DF(Document Frequency): Bir kelimenin tüm koleksiyonda ne kadar geçtiği"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neden Kullanılır?\n",
    "\n",
    "1-) Makine öğrenmesi algoritmaları sayılarla çalışır. Metini sayıya çevirmeliyiz\n",
    "\n",
    "2-)  Önemli kelimeleri vurgular. Nadir ama anlamlı kelimeler yüksek puan(ağırlık) alır\n",
    "\n",
    "3-) Anlamsız kelimeleri bastırır. the,and,is gibi kelimeler üdşük sor alır(CountVectorizer'dan farkı)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temel Adımlar\n",
    "\n",
    "1-) fit_transform() : İlk veri seti için(öğren-dönüştür)\n",
    "\n",
    "2-) transform() : Yeni veriler için (sadece dönüştür)\n",
    "\n",
    "3-) Makine öğrenmesi modeli ile tahmin yapma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Kod Örneği\n",
    "\n",
    "- Kod örneğinde e-posta spam tespiti yaparak gerçek hayata uygun bir problem çözecez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nMultinomialNB algoritması kullanma sebebi metin verileri için uygun olmasıdır\\nSayma verisi(count data) ile çalışır\\nSıfır değerler ile rahatlıkla çalışır(bazı kelimeler dokümanda geçmez)\\nTF-IDF skorları multinominal dağılıma uygundur\\n'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bu örnek e-postaya gelen metinleri analiz ederek spam/ham(normal) sınıflandırması yapar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\" \n",
    "MultinomialNB algoritması kullanma sebebi metin verileri için uygun olmasıdır\n",
    "Sayma verisi(count data) ile çalışır\n",
    "Sıfır değerler ile rahatlıkla çalışır(bazı kelimeler dokümanda geçmez)\n",
    "TF-IDF skorları multinominal dağılıma uygundur\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFormül\\nTF-IDF(t,d) = (t sayısı / toplam kelime sayısı) * log(toplam döküman / t içeren döküman sayısı)\\nAmaç: Önemli ama nadir bulunan kelimelere yüksek puan vermek\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Örnek e-posta veri seti oluştur\n",
    "emails=[\n",
    "    #SPAM e-postalar\n",
    "    \"Congratulations! You won $1000000! Click here to claim your prize now!\",\n",
    "    \"URGENT: Your account will be closed. Send your password immediately.\",\n",
    "    \"Free money! Win big! Casino online! Click now for amazing offers!\",\n",
    "    \"Viagra cheap! Best prices! Order now! Special discount today only!\",\n",
    "    \"You are selected winner! Claim $50000 prize money today! Act fast!\",\n",
    "    \"Make money fast! Work from home! Earn $5000 weekly! No experience needed!\",\n",
    "    \"FREE! FREE! FREE! Download now! Limited time offer! Click here!\",\n",
    "    \"Your credit approved! $10000 loan instant approval! Apply now!\",\n",
    "\n",
    "    # HAM(normal) epostalar\n",
    "\n",
    "    \"Hi Trump, can we schedule a meeting for tomorrow afternoon?\",\n",
    "    \"The quarterly report is ready for review. Please check the attached file.\",\n",
    "    \"Thank you for your presentation today. It was very informative.\",\n",
    "    \"Reminder: Team lunch is scheduled for Friday at 12:30 PM.\",\n",
    "    \"Please find the updated project timeline in the attachment.\",\n",
    "    \"Good morning! How was your weekend? Looking forward to our call.\",\n",
    "    \"The software update has been completed successfully on all systems.\",\n",
    "    \"Your order has been shipped and will arrive within 3-5 business days.\"\n",
    "\n",
    "]\n",
    "\n",
    "#Etiketler (0: Ham, 1: SPAM)\n",
    "labels=[1,1,1,1,1,1,1,1,#İLk 8 SPAM\n",
    "        0,0,0,0,0,0,0,0] # Son 8 Ham\n",
    "\n",
    "\"\"\"\n",
    "Formül\n",
    "TF-IDF(t,d) = (t sayısı / toplam kelime sayısı) * log(toplam döküman / t içeren döküman sayısı)\n",
    "Amaç: Önemli ama nadir bulunan kelimelere yüksek puan vermek\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TfidfVectorizer oluştur ve parametreleri açıkla\n",
    "\n",
    "vectorizer=TfidfVectorizer(\n",
    "    max_features=60 ,  #En fazla 60 özellik(kelime) kullan\n",
    "    stop_words=\"english\",   #İngilizce stop words'leri kaldır(a,an,the,is vs) kaldır\n",
    "    lowercase=True,   #Tüm harfleri küçük harfe çevir\n",
    "    ngram_range=(1,2)   #Tek kelimeler(1-gram) ve kelime çiftleri (2-gram) kullan\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orijinal metin sayısı: 16\n",
      "Oluşturan vektör boyutu: (16, 60)\n",
      "Her metin 60 boyutlu bir vektör haline geldi\n",
      "Kullanılan kelimelerin ilk 20 tanesi ['10000' 'claim' 'click' 'fast' 'free' 'free free' 'meeting tomorrow'\n",
      " 'money' 'money fast' 'money today' 'money win' 'morning'\n",
      " 'morning weekend' 'needed' 'offer' 'offer click' 'offers' 'online'\n",
      " 'online click' 'order']\n"
     ]
    }
   ],
   "source": [
    "# Metinleri vektöre çevir\n",
    "\n",
    "#fit_transform ile hem öğren hem dönüştür\n",
    "X=vectorizer.fit_transform(emails)\n",
    "print(f\"Orijinal metin sayısı: {len(emails)}\")\n",
    "print(f\"Oluşturan vektör boyutu: {X.shape}\")\n",
    "print(f\"Her metin {X.shape[1]} boyutlu bir vektör haline geldi\")\n",
    "\n",
    "#Hangi kelimeler kullanıldı\n",
    "feature_names=vectorizer.get_feature_names_out()\n",
    "print(f\"Kullanılan kelimelerin ilk 20 tanesi {feature_names[:20]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÖRNEK METİN ANALİZİ\n",
      "Örnek metin: Congratulations! You won $1000000! Click here to claim your prize now!\n",
      "Bu metin 60 boyutlu vektöre dönüştü\n",
      "Bu metindeli en önemli 10 kelime ve TF-IDF skorları\n",
      "prize : 0.5975432755013906\n",
      "claim : 0.5975432755013906\n",
      "click : 0.5346812768426984\n"
     ]
    }
   ],
   "source": [
    "# Bir tane örnek metnin nasıl vektöre çevrildiğini görelim\n",
    "print(\"ÖRNEK METİN ANALİZİ\")\n",
    "sample_text=emails[0]#ilk spam maili\n",
    "sample_vector=X[0].toarray()[0] #bu metnin vektör hali\n",
    "print(f\"Örnek metin: {sample_text}\")\n",
    "print(f\"Bu metin {len(sample_vector)} boyutlu vektöre dönüştü\")\n",
    "\n",
    "# Örnek metindeki en önemli(en yüksek skorlu) 10 kelimeyi gösteer\n",
    "top_indices=sample_vector.argsort()[-10:][::-1]\n",
    "print(\"Bu metindeli en önemli 10 kelime ve TF-IDF skorları\")\n",
    "for idx in top_indices:\n",
    "    if sample_vector[idx]>0:\n",
    "        print(f\"{feature_names[idx]} : {sample_vector[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti: 10 örnekten oluşuyor\n",
      "Test seti 6 örnekten oluşuyor\n",
      "Model doğruluğu : 0.83\n"
     ]
    }
   ],
   "source": [
    "# Makine öğrenmesi modeli oluştur\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,labels,stratify=labels,test_size=0.33,random_state=42)\n",
    "print(f\"Eğitim seti: {X_train.shape[0]} örnekten oluşuyor\")\n",
    "print(f\"Test seti {X_test.shape[0]} örnekten oluşuyor\")\n",
    "\n",
    "#Naive bayes sınıflandırıcısı ile modeli eğit\n",
    "model=MultinomialNB()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "#Test seti üzerinden tahmin yap\n",
    "y_pred=model.predict(X_test)\n",
    "accuracy=accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(f\"Model doğruluğu : {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detaylı analiz\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         HAM       0.75      1.00      0.86         3\n",
      "        SPAM       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.83         6\n",
      "   macro avg       0.88      0.83      0.83         6\n",
      "weighted avg       0.88      0.83      0.83         6\n",
      "\n",
      "--------------------------------------------------------------\n",
      "Karışıklık Matrisi\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 0],\n",
       "       [1, 2]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sonuçları analiz et\n",
    "print(\"Detaylı analiz\")\n",
    "print(classification_report(y_test,y_pred,target_names=[\"HAM\",\"SPAM\"]))\n",
    "\n",
    "print(\"--\"*31)\n",
    "#Karışıklık matrisi\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "print(\"Karışıklık Matrisi\")\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E-Posta Contact me\n",
      "Tahmin: HAM (Spam olma olasılığı: 50.00)\n",
      "E-Posta WIN BIG MONEY NOW! CLICK HERE FOT INSTANT CASH\n",
      "Tahmin: SPAM (Spam olma olasılığı: 66.40)\n",
      "E-Posta The meeting has been reschueduled to 3 Pm tomorrow\n",
      "Tahmin: HAM (Spam olma olasılığı: 49.83)\n"
     ]
    }
   ],
   "source": [
    "# Yeni e-posta örnekleri ile test et\n",
    "new_emails=[\"Contact me\",\n",
    "            \"WIN BIG MONEY NOW! CLICK HERE FOT INSTANT CASH\",\n",
    "            \"The meeting has been reschueduled to 3 Pm tomorrow\"]\n",
    "\n",
    "# Yeni mailleri aynı vektorizastyon ile dönüştür\n",
    "# fit_transform değil sadece transform\n",
    "new_X=vectorizer.transform(new_emails)\n",
    "new_predictions=model.predict(new_X)\n",
    "new_probabalities=model.predict_proba(new_X)\n",
    "\n",
    "for i,email in enumerate(new_emails):\n",
    "    prediction= \"SPAM\" if new_predictions[i]== 1 else \"HAM\"\n",
    "    spam_prob=new_probabalities[i][1] * 100\n",
    "    print(f\"E-Posta {email}\")\n",
    "    print(f\"Tahmin: {prediction} (Spam olma olasılığı: {spam_prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM tespiti için en etkili kelimeler\n",
      "prize: 0.6555\n",
      "claim: 0.6555\n",
      "click: 0.4215\n",
      "offer click: -0.0068\n",
      "prices: 0.3270\n",
      "presentation today: -0.4888\n",
      "presentation: -0.4888\n",
      "pm: -0.0068\n",
      "password immediately: -0.0068\n",
      "password: -0.0068\n"
     ]
    }
   ],
   "source": [
    "# En önemli kelimeleri bul\n",
    "feature_importance=model.feature_log_prob_[1] - model.feature_log_prob_[0]\n",
    "top_spam_indices=feature_importance.argsort()[-10:][::1]\n",
    "\n",
    "print(\"SPAM tespiti için en etkili kelimeler\")\n",
    "for idx in top_indices:\n",
    "    print(f\"{feature_names[idx]}: {feature_importance[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zgncn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
